{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d1cbf8b",
   "metadata": {},
   "source": [
    "We can access Language models through 3 methods:\n",
    "\n",
    "1) Paid API calls (Open AI, Anthropic, Mixtral)\n",
    "2) Open Source API calls (Groq, Huggingface)\n",
    "3) Ollama (Using LLMs - Locally (Requires good system configuration))\n",
    "\n",
    "For Ollama refer : (https://github.com/ollama/ollama)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9e0398",
   "metadata": {},
   "source": [
    "Groq : https://groq.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc111808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the chat model to interact with foundational models offered by Groq\n",
    "from langchain_groq import ChatGroq \n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#Importing a Chat Prompt Template for giving instruction through the chat model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser #Explore Langchain docs for more knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a6dba",
   "metadata": {},
   "source": [
    "Langchain Reference Docs: (Output parsers : https://python.langchain.com/docs/concepts/output_parsers/,\n",
    "https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3262cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the .env file and getting the API key stored in environment Variable\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bb46ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bharath.sr.lv\\Desktop\\Agentic AI -LP\\AgenticAIlp\\lib\\site-packages\\langchain_groq\\chat_models.py:370: UserWarning: WARNING! max_completion_tokens is not default parameter.\n",
      "                    max_completion_tokens was transferred to model_kwargs.\n",
      "                    Please confirm that max_completion_tokens is what you intended.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000029B9D587DF0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000029B9DA5D1E0>, model_name='deepseek-r1-distill-llama-70b', temperature=0.1, model_kwargs={'max_completion_tokens': 1024}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  ChatGroq(\n",
    "    model = \"deepseek-r1-distill-llama-70b\",\n",
    "    temperature = 0.1, ## Controls the Model's output creativity\n",
    "    max_completion_tokens=1024\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48488014",
   "metadata": {},
   "outputs": [],
   "source": [
    "Json_output_parser = JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a4be04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\",\"You are an expert resume parser that extracts structured data.\"),\n",
    "        (\"user\", \"\"\"Given the resume text below, extract:\n",
    "        - job_title: The primary job title\n",
    "        - years_experience: Total years of experience (numeric)\n",
    "        - skills: List of skills\n",
    "\n",
    "        Return **only** a valid JSON object with keys: job_title, years_experience, skills.\n",
    "\n",
    "        {format_instructions}\n",
    "\n",
    "        Resume: {resume_text}\n",
    "        \"\"\")]\n",
    "        ).partial(format_instructions=Json_output_parser.get_format_instructions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66fdb5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_title': 'senior data analyst',\n",
       " 'years_experience': 6,\n",
       " 'skills': ['Python', 'SQL', 'data visualization', 'communication', 'agile']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | Json_output_parser\n",
    "\n",
    "chain.invoke(\"\"\"\n",
    "Mr.Chris is a senior data analyst with over 6 years of experience in Python, SQL, and data visualization. He also has strong communication skills and has worked in agile teams.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8aca2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgenticAIlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
